# backend/ask_llm.py

import os
import json
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from backend.get_flights import load_flight_data  # Veri yÃ¼kleme fonksiyonu

# Ortam deÄŸiÅŸkenlerini yÃ¼kle
load_dotenv()

# OpenRouter API ayarlarÄ±
os.environ["OPENAI_API_BASE"] = "https://openrouter.ai/api/v1"
os.environ["OPENAI_API_KEY"] = os.getenv("OPENROUTER_API_KEY")


def analyze_flight_data(query: str, flight_data: list) -> str:
    """
    UÃ§uÅŸ verilerini analiz ederek kullanÄ±cÄ± sorusuna uygun sonuÃ§ dÃ¶ndÃ¼rÃ¼r
    """
    if not flight_data:
        return "Åu anda analiz edilecek uÃ§uÅŸ verisi bulunmuyor."

    # Temel istatistikler hesapla
    total_flights = len(flight_data)

    # Sadece geÃ§erli verileri filtrele
    valid_flights = [f for f in flight_data if f.get('velocity') and f.get('altitude')]

    if not valid_flights:
        return f"Toplam {total_flights} uÃ§uÅŸ verisi var ancak analiz iÃ§in gerekli bilgiler eksik."

    # Ä°statistikler
    velocities = [f['velocity'] for f in valid_flights if f['velocity'] is not None]
    altitudes = [f['altitude'] for f in valid_flights if f['altitude'] is not None]
    countries = [f['origin_country'] for f in valid_flights if f.get('origin_country')]

    stats = {
        "toplam_ucus": total_flights,
        "gecerli_ucus": len(valid_flights),
        "ortalama_hiz": sum(velocities) / len(velocities) if velocities else 0,
        "maksimum_hiz": max(velocities) if velocities else 0,
        "minimum_hiz": min(velocities) if velocities else 0,
        "ortalama_irtifa": sum(altitudes) / len(altitudes) if altitudes else 0,
        "maksimum_irtifa": max(altitudes) if altitudes else 0,
        "minimum_irtifa": min(altitudes) if altitudes else 0,
        "ulke_sayisi": len(set(countries)) if countries else 0,
        "en_fazla_ulke": max(set(countries), key=countries.count) if countries else "Bilinmiyor"
    }

    return stats


def build_enhanced_prompt(user_query: str, flight_data: list) -> str:
    analysis = analyze_flight_data(user_query, flight_data)

    if isinstance(analysis, str):
        return f"""
Sen bir uÃ§uÅŸ verisi analiz asistanÄ±sÄ±n. KullanÄ±cÄ±nÄ±n sorusuna mevcut veriler Ã¼zerinden cevap ver.

MEVCUT DURUM: {analysis}

KullanÄ±cÄ± Sorusu: {user_query}

LÃ¼tfen bu durumu aÃ§Ä±klayarak kullanÄ±cÄ±ya bilgi ver.
"""

    # ğŸ”½ SADELEÅTÄ°RÄ°LMÄ°Å TÃœM UÃ‡UÅLARI hazÄ±rla
    simplified_data = [
        {
            "callsign": f.get("callsign"),
            "origin_country": f.get("origin_country"),
            "velocity": f.get("velocity"),
            "altitude": f.get("altitude")
        }
        for f in flight_data
        if f.get("velocity") is not None and f.get("altitude") is not None
    ]

    return f"""
Sen bir uÃ§uÅŸ verisi analiz asistanÄ±sÄ±n. AÅŸaÄŸÄ±daki uÃ§uÅŸ verileri Ã¼zerinden kullanÄ±cÄ±nÄ±n sorusuna cevap ver.

ğŸ“Š GÃœNCEL Ä°STATÄ°STÄ°KLER:
- Toplam uÃ§uÅŸ sayÄ±sÄ±: {analysis['toplam_ucus']}
- Analiz edilebilir uÃ§uÅŸ: {analysis['gecerli_ucus']}
- Ortalama hÄ±z: {analysis['ortalama_hiz']:.2f} m/s
- Maksimum hÄ±z: {analysis['maksimum_hiz']:.2f} m/s
- Ortalama irtifa: {analysis['ortalama_irtifa']:.2f} m
- Maksimum irtifa: {analysis['maksimum_irtifa']:.2f} m
- Ãœlke sayÄ±sÄ±: {analysis['ulke_sayisi']}
- En Ã§ok uÃ§uÅŸ yapan Ã¼lke: {analysis['en_fazla_ulke']}

ğŸ“¦ TÃœM UÃ‡UÅ VERÄ°LERÄ°:
{json.dumps(simplified_data, indent=2, ensure_ascii=False)}

KullanÄ±cÄ± Sorusu: {user_query}

LÃ¼tfen sadece yukarÄ±daki verilere dayanarak doÄŸru, kÄ±sa ve anlaÅŸÄ±lÄ±r bir cevap ver.
VarsayÄ±m yapma. Sadece veriye dayalÄ± konuÅŸ.
"""


def ask_llm(query: str) -> str:
    """
    LLM'e gerÃ§ek uÃ§uÅŸ verileriyle birlikte soru sor
    """
    try:
        # Ã–nce uÃ§uÅŸ verilerini yÃ¼kle
        print("[DEBUG] LLM iÃ§in uÃ§uÅŸ verileri yÃ¼kleniyor...")
        flight_data = load_flight_data()

        if not flight_data:
            return "âŒ Åu anda analiz edilecek uÃ§uÅŸ verisi bulunmuyor. LÃ¼tfen Ã¶nce '/send-flight' endpoint'ini kullanarak veri toplayÄ±n."

        print(f"[DEBUG] LLM'e {len(flight_data)} uÃ§uÅŸ verisi gÃ¶nderilecek")

        # LLM'i baÅŸlat
        llm = ChatOpenAI(
            model="google/gemma-3-27b-it:free",
            temperature=0.3,
            max_tokens=500,
        )

        # ZenginleÅŸtirilmiÅŸ prompt ile soru sor
        enhanced_prompt = build_enhanced_prompt(query, flight_data)
        response = llm([HumanMessage(content=enhanced_prompt)])

        result = response.content if hasattr(response, "content") else response.choices[0].message.content

        return f"ğŸ“Š **Analiz Sonucu** (Toplam {len(flight_data)} uÃ§uÅŸ verisi Ã¼zerinden):\n\n{result}"

    except Exception as e:
        print(f"[ERROR] LLM isteÄŸi hata: {e}")
        return f"âŒ [HATA] LLM analizi baÅŸarÄ±sÄ±z oldu: {e}"


# Test iÃ§in yardÄ±mcÄ± fonksiyon
def test_llm_with_data():
    """
    LLM'i test etmek iÃ§in Ã¶rnek sorular
    """
    test_queries = [
        "En yÃ¼ksek irtifada uÃ§an uÃ§ak hangisi?",
        "Hangi Ã¼lkeden en Ã§ok uÃ§uÅŸ var?",
        "Ortalama uÃ§uÅŸ hÄ±zÄ± nedir?",
        "Toplam kaÃ§ uÃ§uÅŸ verisi var?"
    ]

    print("=== LLM TEST BAÅLADI ===")
    for query in test_queries:
        print(f"\nğŸ” Soru: {query}")
        result = ask_llm(query)
        print(f"ğŸ’¡ Cevap: {result}")
    print("\n=== LLM TEST BÄ°TTÄ° ===")


if __name__ == "__main__":
    # Direkt Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda test yap
    test_llm_with_data()